# -*- coding: utf-8 -*-
"""KMeans_Clustering_Countries_Analysis_Based_On_Development.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tZVj305ucwKAVmUlwiZHm_02HGT1OR7x
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Country-data.csv')
df

df.shape

df.info()

df.isnull().sum()

# df[df.duplicated()] - To show all duplicated rows present
df.duplicated()

# df.drop_duplicates() - To drop all the duplicated values

df.describe().T

plt.figure(figsize = (20,10))
sns.heatmap(df.corr(),annot=True)
plt.show()

cols = list(df_new.columns)
for col in cols:
  sns.violinplot(y=df[col])
  plt.show()

df_new = df.drop(columns=['country','gdpp'])
df_new.head()

# Observation - Mean(the column or all the observations) / Std Deviation of it
scaler = StandardScaler()
df_scaled = pd.DataFrame(scaler.fit_transform(df_new),columns = df_new.columns)
df_scaled

# Always best practice to have a copy of your scaled data because sometimes you might lose it during model creation and if that happens you've to again scale your data. Hence to avoid that it's better to have a scaled copy of your data!
df_scaled_copy = df_scaled.copy(deep=True)
df_scaled_copy

sse = []
for k in range (1,10):
  kmeans = KMeans(n_clusters = k, random_state = 1).fit(df_scaled)
  sse.append(kmeans.inertia_)
  print(kmeans.inertia_)

plt.figure(figsize=(10,5))
plt.plot(list(range(1,10)),sse,marker='o',alpha=0.5,color='red')
plt.xlabel('Clusters')
plt.ylabel('Sum Of Squared Errors (SSE)')
plt.yticks(rotation=90)
plt.legend('Curve',loc='upper center')
plt.grid(True)
plt.show()

# Silhouette Score calculation
# It is the score measure of distance between each clusters and the most optimal or best value is 1 and worst value is -1 while 0 being the average value.
# More closer the silhouette score to 1 the better is the model for the particular value of cluster K
sil = []
for k in range(2,10):
  kmeans = KMeans(n_clusters = k, random_state = 1).fit(df_scaled)
  labels = kmeans.predict(df_scaled)
  sil.append(silhouette_score(df_scaled,labels))

plt.figure(figsize=(10,5))
plt.plot(list(range(2,10)),sil)
plt.xlabel('Clusters')
plt.ylabel('silhouette score')
plt.yticks(rotation=90)
plt.show()

kmeans = KMeans(n_clusters = 3,random_state=1).fit(df_scaled)
df['KMeans_Labels'] = kmeans.predict(df_scaled)
df

mean = df.groupby('KMeans_Labels').mean()
median = df.groupby('KMeans_Labels').median()
df_compare = pd.concat([mean,median],axis=0)
df_compare.index = ['g0 mean', 'g1 mean', 'g2 mean', 'g0 median', 'g1 median', 'g2 median']
df_compare.T

category = []
for index, row in df.iterrows():
  if(row['KMeans_Labels'] == 0):
    category.append('Developing')
  elif(row['KMeans_Labels'] == 1):
    category.append('Under-Developed')
  else:
    category.append('Developed')
df['Category'] = category
df

df[df['Category'] == 'Developed']

df[df['Category'] == 'Developing']

df[df['Category'] == 'Under-Developed']

cols = list(df_new.columns)
for col in cols:
  sns.boxplot(x='KMeans_Labels',y=col, data=df)
  plt.show()

cols = list(df_new.columns)
for col in cols:
  sns.lineplot(data=df, x= col, y='KMeans_Labels')
  plt.show()

cols = list(df_new.columns)
for col in cols:
  sns.violinplot(data=df, x= 'KMeans_Labels', y=col)
  plt.show()

cols = list(df_new.columns)
for col in cols:
  sns.scatterplot(data = df, x=col, y='gdpp', hue='KMeans_Labels', palette='Dark2')
  plt.show()

cols = list(df_new.columns)
for col in cols:
  plt.scatter(df['KMeans_Labels'],col)
  plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red')
  plt.show()